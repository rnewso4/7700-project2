{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebc97dbb-198b-4b7d-987f-f096ec215d43",
   "metadata": {},
   "source": [
    "<h1>Load Tokenizer and Instantiate Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6b56093-4905-4a68-aebb-1f061d4ff990",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_model import TransformerLanguageModel\n",
    "import torch\n",
    "import sentencepiece as spm\n",
    "from transformers import BertTokenizer  # Or any other tokenizer you prefer\n",
    "\n",
    "# Trained tokenizer\n",
    "sp = spm.SentencePieceProcessor()\n",
    "model_prefix = \"bpe_tokenizer\"\n",
    "sp.load(f'{model_prefix}.model')\n",
    "tokenizer = sp\n",
    "\n",
    "device = \"mps\"\n",
    "\n",
    "# transformer_model = TransformerLanguageModel(tokenizer.get_piece_size())\n",
    "# transformer_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82e33a1-e4f6-438f-a9ab-b52ab40ac1f4",
   "metadata": {},
   "source": [
    "<h1>Load Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9774d53-d51e-49ec-8c83-51848ede7951",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import sentencepiece as spm\n",
    "from pathlib import Path\n",
    "\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_NAME = \"transformer_language_model.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "transformer_model = TransformerLanguageModel(sp.get_piece_size()).to(\"mps\")\n",
    "\n",
    "# Load the saved state_dict of module_0 \n",
    "transformer_model.load_state_dict(torch.load(f=MODEL_SAVE_PATH, weights_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf44513f-b8bb-4352-8429-b0e143aeab2f",
   "metadata": {},
   "source": [
    "<h1>Train Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62bc10e7-efac-4d53-8f82-2dc3c3ea2e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from textdataset import TextDataSet\n",
    "# import os\n",
    "\n",
    "# training_losses, validation_losses = TextDataSet(os.getcwd()+\"/data/train.jsonl\", sp).train_model(transformer_model, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5492336b-2396-459e-b944-e746966f7124",
   "metadata": {},
   "source": [
    "<h1>Visualize</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f44b15fa-50a7-4dc9-8e82-1a654c1ef627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# # plot the loss curves\n",
    "# plt.plot(training_losses, label=\"Train loss\")\n",
    "# plt.plot(validation_losses, label=\"Validation loss\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# plt.xlabel(\"Epochs\")\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ec397b-04e0-4030-a16e-6a67a1c93ac2",
   "metadata": {},
   "source": [
    "<h1>Save Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02b59516-59d7-4f2d-a214-906555d2df98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Saving our PyTorch model\n",
    "# from pathlib import Path\n",
    "\n",
    "# # 1. Create model's directory\n",
    "# MODEL_PATH = Path(\"models\")\n",
    "# MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# # 2. Create model save path\n",
    "# MODEL_NAME = \"transformer_language_model.pth\"\n",
    "# MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "# # 3. Save the model state dict\n",
    "# torch.save(obj=transformer_model.state_dict(),f=MODEL_SAVE_PATH)\n",
    "# print(\"saving complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e943ea-4f33-47c5-a095-bbca6213a908",
   "metadata": {},
   "source": [
    "<h1>Evaluate Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f3d2219-1f6d-4f32-b718-98a6bae79280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from textdataset import TextDataSet\n",
    "# import os\n",
    "\n",
    "# tds = TextDataSet(os.getcwd()+\"/data/train.jsonl\", sp).evalutate_model(transformer_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf0b79c-eedc-4ea4-b739-6cd4c05c0641",
   "metadata": {},
   "source": [
    "<h1>Generate from prompts</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f3a9c7a-5b27-4686-a145-615f2bff53ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: No, but of the last. I shall, and the evening, and in the rest, and he, and had ind. <bos>N. He had no longer to the matter. He is to the room, but to the matter.\n"
     ]
    }
   ],
   "source": [
    "# Example usage of the generate method\n",
    "#prompt = \"unless he wished to show that he, too, could have an opinion, but he urged that at this point the army should unite and there await the enemy. It was plain that Armfeldt had thought out that plan long ago and now expounded it not so much to answer the questions putwhich, in fact, his plan did\"\n",
    "prompt = \"Will I pass this class?\"\n",
    "generated_text = transformer_model.generate(sp, prompt, max_length=50, eos_token_id=2, temperature=0.3, device=\"mps\")\n",
    "print(f\"Generated text: {generated_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16b3983-7b81-46db-8a2b-1d6f807c461a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
