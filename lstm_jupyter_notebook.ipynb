{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c4f2ee4-b946-42f8-b2bd-6ff3725e849c",
   "metadata": {},
   "source": [
    "<h1>Load Tokenizer and Instantiate Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "264e8850-1ff5-4439-ad35-0f39a996c644",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lstm_model import LSTMModule\n",
    "import torch\n",
    "import sentencepiece as spm\n",
    "from transformers import BertTokenizer  # Or any other tokenizer you prefer\n",
    "\n",
    "# Trained tokenizer\n",
    "sp = spm.SentencePieceProcessor()\n",
    "model_prefix = \"bpe_tokenizer\"\n",
    "sp.load(f'{model_prefix}.model')\n",
    "tokenizer = sp\n",
    "\n",
    "device = \"mps\"\n",
    "\n",
    "# lstm_model = LSTMModule(tokenizer.get_piece_size())\n",
    "# lstm_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42845861-2678-4109-ab23-dfeb1e35217a",
   "metadata": {},
   "source": [
    "<h1>Load Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12a94875-36ae-40e5-8943-1b0f2c9763fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import sentencepiece as spm\n",
    "from pathlib import Path\n",
    "\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_NAME = \"lstm_language_model.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "lstm_model = LSTMModule(sp.get_piece_size()).to(\"mps\")\n",
    "\n",
    "# Load the saved state_dict of module_0 \n",
    "lstm_model.load_state_dict(torch.load(f=MODEL_SAVE_PATH, weights_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8257e92c-cf50-4ae3-acd4-8cb71e833c3a",
   "metadata": {},
   "source": [
    "<h1>Train Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9d0595c-5071-458a-b99c-68f0cbfc476a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from textdataset import TextDataSet\n",
    "# import os\n",
    "\n",
    "# training_losses, validation_losses = TextDataSet(os.getcwd()+\"/data/train.jsonl\", sp).train_model(lstm_model, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a51c6d8-c171-4f6b-98e8-fb44e3e7b43c",
   "metadata": {},
   "source": [
    "<h1>Visualize</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b188870a-a139-49ec-8042-d974e32f70e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# # plot the loss curves\n",
    "# plt.plot(training_losses, label=\"Train loss\")\n",
    "# plt.plot(validation_losses, label=\"Validation loss\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# plt.xlabel(\"Epochs\")\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa94a92-039f-494b-aa2f-8b9fb7d3ab1f",
   "metadata": {},
   "source": [
    "<h1>Save Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ffaad84-398f-4dec-b08f-934d1360ac71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving complete\n"
     ]
    }
   ],
   "source": [
    "# Saving our PyTorch model\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. Create model's directory\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 2. Create model save path\n",
    "MODEL_NAME = \"lstm_language_model.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "# 3. Save the model state dict\n",
    "torch.save(obj=lstm_model.state_dict(),f=MODEL_SAVE_PATH)\n",
    "print(\"saving complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5ee027-1fe0-48e5-9522-489e6c6ae0b1",
   "metadata": {},
   "source": [
    "<h1>Evaluate Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae18ec40-07fa-4f90-b95d-71339abfb61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from textdataset import TextDataSet\n",
    "# import os\n",
    "\n",
    "# tds = TextDataSet(os.getcwd()+\"/data/train.jsonl\", sp).evalutate_model(lstm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81a08f1-4f1e-4564-b481-46eab0194b92",
   "metadata": {},
   "source": [
    "<h1>Generate from prompts</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6409a0b-6b99-40e3-9692-427d4ba727f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: My condition of right, mothers are very more for her almost in as a State! my fault in the Litopes, dressed for your name should be more on the villages which was absorbed them, so how must say the family. The\n"
     ]
    }
   ],
   "source": [
    "# Example usage of the generate method\n",
    "#prompt = \"unless he wished to show that he, too, could have an opinion, but he urged that at this point the army should unite and there await the enemy. It was plain that Armfeldt had thought out that plan long ago and now expounded it not so much to answer the questions putwhich, in fact, his plan did\"\n",
    "prompt = \"Will I pass this class?\"\n",
    "generated_text = lstm_model.generate(sp, prompt, max_length=50, eos_token_id=2, temperature=0.8, device=\"mps\")\n",
    "print(f\"Generated text: {generated_text}\")\n",
    "# GET THE PROMPT FROM THE LARGE FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab91b795-3e0b-42c3-aa96-42ebac52be84",
   "metadata": {},
   "source": [
    "Output: Generated text: not regard to my masters, those fall is hers in my apple formsically the same soundsing nor strange springrsfather among earth, come with the throat of the Meppt hat or good service yourself I go for her father."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3606789b-7da3-4411-8834-48b6fec8216d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
